# Models and meaning

Positions model fitting as a goal-driven activity and enumerates four archetypal goals: model description (auditing fitted models for interpretability/fairness), data description (summaries that generalize to a population), causal inference (using DAGs and potential outcomes to isolate effects), and out-of-sample prediction. Each subsection defines the estimand implied by the goal and notes the extra assumptions (e.g., representativeness for descriptive work, backdoor paths for causal claims, distributional stability for forecasting). It ties the discussion to later tooling by pointing readers to how predictions/comparisons/slopes instantiate these goals.

The estimand section insists on explicitly naming the quantity of interest before touching an estimator. It formalizes the estimand/estimator/estimate triad, showcases Dawid's "resting stone" quote, and uses examples such as logistic regression coefficients vs. predicted probabilities to show why post-estimation transformations make results legible. The plug-in principle and MLE invariance arguments justify constructing transformed estimators (e.g., risk differences) by applying functions to sample analogues.

The "Table 2 fallacy" and terminology discussion warn that na√Øvely interpreting every coefficient in a single regression (especially control variables or post-treatment variables) leads to contradictory stories. Examples show how the same phrase "marginal effect" can refer to derivatives or averages, underscoring the need for the five-question framework. Functions highlighted: `predictions()`/`comparisons()`/`slopes()` for quantities, `datagrid()` for explicit estimand definitions, and `hypotheses()` for forcing analysts to declare what they are testing.
