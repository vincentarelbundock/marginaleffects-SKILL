## (Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority {.unnumbered}


### Description

Uncertainty estimates are calculated as first-order approximate standard errors for linear or non-linear functions of a vector of random variables with known or estimated covariance matrix. In that sense, <code>hypotheses</code> emulates the behavior of the excellent and well-established car::deltaMethod and car::linearHypothesis functions, but it supports more models; requires fewer dependencies; expands the range of tests to equivalence and superiority/inferiority; and offers convenience features like robust standard errors.

To learn more, read the hypothesis tests vignette, visit the
package website:


<ul>
<li> <a href="https://marginaleffects.com/chapters/hypothesis.html">https://marginaleffects.com/chapters/hypothesis.html</a>

</li>
<li> <a href="https://marginaleffects.com/">https://marginaleffects.com/</a>

</li></ul>

Warning #1: Tests are conducted directly on the scale defined by the <code>type</code> argument. For some models, it can make sense to conduct hypothesis or equivalence tests on the <code>"link"</code> scale instead of the <code>"response"</code> scale which is often the default.

Warning #2: For hypothesis tests on objects produced by the <code>marginaleffects</code> package, it is safer to use the <code>hypothesis</code> argument of the original function.  Using <code>hypotheses()</code> may not work in certain environments, in lists, or when working programmatically with *apply style functions.

Warning #3: The tests assume that the <code>hypothesis</code> expression is (approximately) normally distributed, which for non-linear functions of the parameters may not be realistic. More reliable confidence intervals can be obtained using the <code>inferences()</code> function with <code>method = "boot"</code>.



### Usage

<pre><code class='language-R'>hypotheses(
  model = NULL,
  hypothesis = NULL,
  vcov = TRUE,
  conf_level = NULL,
  df = NULL,
  equivalence = NULL,
  joint = FALSE,
  joint_test = "f",
  multcomp = FALSE,
  numderiv = "fdforward",
  ...
)
</code></pre>


### Arguments

<table role = "presentation">
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="model">model</code></td>
<td>
Model object or object generated by the <code>comparisons()</code>, <code>slopes()</code>, or <code>predictions()</code> functions.
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="hypothesis">hypothesis</code></td>
<td>
specify a hypothesis test or custom contrast using a number , formula, string equation, vector, matrix, or function.


<ul>
<li> Number: The null hypothesis used in the computation of Z and p (before applying <code>transform</code>).

</li>
<li> String: Equation to specify linear or non-linear hypothesis tests. Two-tailed tests must include an equal <code>=</code> sign. One-tailed tests must start with <code>&lt;</code> or <code>&gt;</code>. If the terms in <code>coef(object)</code> uniquely identify estimates, they can be used in the formula. Otherwise, use <code>b1</code>, <code>b2</code>, etc. to identify the position of each parameter. The <code style="white-space: pre;">b*</code> wildcard can be used to test hypotheses on all estimates. When the hypothesis string represents a two-sided equation, the <code>estimate</code> column holds the value of the left side minus the right side of the equation. If a named vector is used, the names are used as labels in the output. Examples:


<ul>
<li> <code>hp = drat</code>

</li>
<li> <code>hp + drat = 12</code>

</li>
<li> <code>b1 + b2 + b3 = 0</code>

</li>
<li> <code style="white-space: pre;">b* / b1 = 1</code>

</li>
<li> <code style="white-space: pre;">&lt;= 0</code>

</li>
<li> <code style="white-space: pre;">&gt;= -3.5</code>

</li>
<li> <code>b1 &gt;= 10</code>

</li></ul>

</li>
<li> Formula: <code>lhs ~ rhs | group</code>


<ul>
<li> <code>lhs</code>


<ul>
<li> <code>ratio</code> (null = 1)

</li>
<li> <code>difference</code> (null = 0)

</li>
<li> Leave empty for default value

</li></ul>

</li>
<li> <code>rhs</code>


<ul>
<li> <code>pairwise</code> and <code>revpairwise</code>: pairwise differences between estimates in each row.

</li>
<li> <code>reference</code>: differences between the estimates in each row and the estimate in the first row.

</li>
<li> <code>sequential</code>: difference between an estimate and the estimate in the next row.

</li>
<li> <code>meandev</code>: difference between an estimate and the mean of all estimates.

</li>
<li> <code>meanotherdev</code>: difference between an estimate and the mean of all other estimates, excluding the current one.

</li>
<li> <code>poly</code>: polynomial contrasts, as computed by the <code>stats::contr.poly()</code> function.

</li>
<li> <code>helmert</code>: Helmert contrasts, as computed by the <code>stats::contr.helmert()</code> function. Contrast 2nd level to the first, 3rd to the average of the first two, and so on.

</li>
<li> <code>trt_vs_ctrl</code>: difference between the mean of estimates (except the first) and the first estimate.

</li>
<li> <code>I(fun(x))</code>: custom function to manipulate the vector of estimates <code>x</code>. The function <code>fun()</code> can return multiple (potentially named) estimates.

</li></ul>

</li>
<li> <code>group</code> (optional)


<ul>
<li> Column name of <code>newdata</code>. Conduct hypothesis tests withing subsets of the data.

</li></ul>

</li>
<li> Examples:


<ul>
<li> <code>~ poly</code>

</li>
<li> <code>~ sequential | groupid</code>

</li>
<li> <code>~ reference</code>

</li>
<li> <code>ratio ~ pairwise</code>

</li>
<li> <code>difference ~ pairwise | groupid</code>

</li>
<li> <code>~ I(x - mean(x)) | groupid</code>

</li>
<li> <code style="white-space: pre;">~ I(\(x) c(a = x[1], b = mean(x[2:3]))) | groupid</code>

</li></ul>

</li></ul>

</li>
<li> Matrix or Vector: Each column is a vector of weights. The the output is the dot product between these vectors of weights and the vector of estimates. The matrix can have column names to label the estimates.

</li>
<li> Function:


<ul>
<li> Accepts an argument <code>x</code>: object produced by a <code>marginaleffects</code> function or a data frame with column <code>rowid</code> and <code>estimate</code>

</li>
<li> Returns a data frame with columns <code>term</code> and <code>estimate</code> (mandatory) and <code>rowid</code> (optional).

</li>
<li> The function can also accept optional input arguments: <code>newdata</code>, <code>by</code>, <code>draws</code>.

</li>
<li> This function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use <code>get_draws()</code> to extract and manipulate the draws directly.

</li></ul>

</li>
<li> See the Examples section below and the vignette: <a href="https://marginaleffects.com/chapters/hypothesis.html">https://marginaleffects.com/chapters/hypothesis.html</a>

</li>
<li> Warning: When calling <code>predictions()</code> with <code>type="invlink(link)"</code> (the default in some models), <code>hypothesis</code> is tested and p values are computed on the link scale.

</li></ul>
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="vcov">vcov</code></td>
<td>
Type of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:


<ul>
<li> FALSE: Do not compute standard errors. This can speed up computation considerably.

</li>
<li> TRUE: Unit-level standard errors using the default <code>vcov(model)</code> variance-covariance matrix.

</li>
<li> String which indicates the kind of uncertainty estimates to return.


<ul>
<li> Heteroskedasticity-consistent: <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>

</li>
<li> Heteroskedasticity and autocorrelation consistent: <code>"HAC"</code>

</li>
<li> Mixed-Models degrees of freedom: &quot;satterthwaite&quot;, &quot;kenward-roger&quot;

</li>
<li> Other: <code>"NeweyWest"</code>, <code>"KernHAC"</code>, <code>"OPG"</code>. See the <code>sandwich</code> package documentation.

</li>
<li> &quot;rsample&quot;, &quot;boot&quot;, &quot;fwb&quot;, and &quot;simulation&quot; are passed to the <code>method</code> argument of the <code>inferences()</code> function. To customize the bootstrap or simulation process, call <code>inferences()</code> directly.

</li></ul>

</li>
<li> One-sided formula which indicates the name of cluster variables (e.g., <code>~unit_id</code>). This formula is passed to the <code>cluster</code> argument of the <code>sandwich::vcovCL</code> function.

</li>
<li> Square covariance matrix

</li>
<li> Function which returns a covariance matrix (e.g., <code>stats::vcov(model)</code>)

</li></ul>
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="conf_level">conf_level</code></td>
<td>
NULL or numeric value between 0 and 1. Confidence level to use to build a confidence interval. When <code>NULL</code> and <code>model</code> was generated by <code>marginaleffects</code>, the confidence level is taken from the <code>conf_level</code> attribute of the model. Otherwise, the default value is 0.95.
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="df">df</code></td>
<td>
Degrees of freedom used to compute p values and confidence intervals.


<ul>
<li> A single numeric value between 1 and <code>Inf</code>, or a numeric vector with length equal to the number of rows in the output. When <code>df</code> is <code>Inf</code>, the normal distribution is used. When <code>df</code> is finite, the <code>t</code> distribution is used.

</li>
<li> &quot;residual&quot;: Calls insight::get_df to extract degrees of freedom from the model automatically.

</li>
<li> When using <code>joint_test="f"</code>, the <code>df</code> argument should be a numeric vector of length 2.

</li></ul>
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="equivalence">equivalence</code></td>
<td>
Numeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. For bayesian models, this report the proportion of posterior draws in the interval and the ROPE. See Details section below.
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="joint">joint</code></td>
<td>
Joint test of statistical significance. The null hypothesis value can be set using the <code>hypothesis</code> argument.


<ul>
<li> FALSE: Hypotheses are not tested jointly.

</li>
<li> TRUE: All parameters are tested jointly.

</li>
<li> String: A regular expression to match parameters to be tested jointly. <code>grep(joint, perl = TRUE)</code>

</li>
<li> Character vector of parameter names to be tested. Characters refer to the names of the vector returned by <code>marginaleffects::get_coef(object)</code>.

</li>
<li> Integer vector of indices. Which parameters positions to test jointly.

</li>
<li> Note: When using the <code>joint</code> argument, the <code>hypothesis</code> argument is limited to <code>NULL</code> or numeric values. Users can chain multiple <code>hypotheses()</code> for complex joint hypothesis tests.

</li></ul>
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="joint_test">joint_test</code></td>
<td>
A character string specifying the type of test, either &quot;f&quot; or &quot;chisq&quot;. The null hypothesis is set by the <code>hypothesis</code> argument, with default null equal to 0 for all parameters.
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="multcomp">multcomp</code></td>
<td>
Logical or string. If <code>TRUE</code> or string, apply multiple comparison adjustment to the p values and report family-wise confidence intervals. Valid strings: &quot;holm&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;, &quot;fdr&quot;, &quot;single-step&quot;, &quot;Shaffer&quot;, &quot;Westfall&quot;, &quot;free&quot;. When <code>multcomp</code> is <code>TRUE</code>, the &quot;holm&quot; method is used.
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="numderiv">numderiv</code></td>
<td>
string or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.


<ul>
<li> &quot;fdforward&quot;: finite difference method with forward differences (default)

</li>
<li> &quot;fdcenter&quot;: finite difference method with central differences

</li>
<li> &quot;richardson&quot;: Richardson extrapolation method

</li>
<li> Extra arguments can be specified by passing a list to the <code>numDeriv</code> argument, with the name of the method first and named arguments following, ex: <code>numderiv=list("fdcenter", eps = 1e-5)</code>. When an unknown argument is used, <code>marginaleffects</code> prints the list of valid arguments for each method.

</li></ul>
</td></tr>
<tr><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code id="...">...</code></td>
<td>
Additional arguments are passed to the <code>predict()</code> method
supplied by the modeling package.These arguments are particularly useful
for mixed-effects or bayesian models (see the online vignettes on the
<code>marginaleffects</code> website). Available arguments can vary from model to
model, depending on the range of supported arguments by each modeling
package. See the &quot;Model-Specific Arguments&quot; section of the
<code>?slopes</code> documentation for a non-exhaustive list of available
arguments.
</td></tr>
</table>


### Joint hypothesis tests

The test statistic for the joint Wald test is calculated as (R * theta_hat - r)' * inv(R * V_hat * R') * (R * theta_hat - r) / Q,
where theta_hat is the vector of estimated parameters, V_hat is the estimated covariance matrix, R is a Q x P matrix for testing Q hypotheses on P parameters,
r is a Q x 1 vector for the null hypothesis, and Q is the number of rows in R. If the test is a Chi-squared test, the test statistic is not normalized.

The p-value is then calculated based on either the F-distribution (for F-test) or the Chi-squared distribution (for Chi-squared test).
For the F-test, the degrees of freedom are Q and (n - P), where n is the sample size and P is the number of parameters.
For the Chi-squared test, the degrees of freedom are Q.



### Equivalence, Inferiority, Superiority

$\theta$ is an estimate, $\sigma_\theta$ its estimated standard error, and $[a, b]$ are the bounds of the interval supplied to the <code>equivalence</code> argument.

Non-inferiority:


<ul>
<li> $H_0$: $\theta \leq a$

</li>
<li> $H_1$: $\theta > a$

</li>
<li> $t=(\theta - a)/\sigma_\theta$

</li>
<li> p: Upper-tail probability

</li></ul>

Non-superiority:


<ul>
<li> $H_0$: $\theta \geq b$

</li>
<li> $H_1$: $\theta < b$

</li>
<li> $t=(\theta - b)/\sigma_\theta$

</li>
<li> p: Lower-tail probability

</li></ul>

Equivalence: Two One-Sided Tests (TOST)


<ul>
<li> p: Maximum of the non-inferiority and non-superiority p values.

</li></ul>

Thanks to Russell V. Lenth for the excellent <code>emmeans</code> package and documentation which inspired this feature.



### Examples
```{r, warning=FALSE, message=FALSE, eval=TRUE}
library("marginaleffects")

mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)

hypotheses(mod)

# Test of equality between coefficients
hypotheses(mod, hypothesis = "hp = wt")

# Non-linear function
hypotheses(mod, hypothesis = "exp(hp + wt) = 0.1")

# Robust standard errors
hypotheses(mod, hypothesis = "hp = wt", vcov = "HC3")

# b1, b2, ... shortcuts can be used to identify the position of the
# parameters of interest in the output of
hypotheses(mod, hypothesis = "b2 = b3")

# wildcard
hypotheses(mod, hypothesis = "b* / b2 = 1")

# term names with special characters have to be enclosed in backticks
hypotheses(mod, hypothesis = "`factor(cyl)6` = `factor(cyl)8`")

mod2 <- lm(mpg ~ hp * drat, data = mtcars)
hypotheses(mod2, hypothesis = "`hp:drat` = drat")

# predictions(), comparisons(), and slopes()
mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)
cmp <- comparisons(mod, newdata = "mean")
hypotheses(cmp, hypothesis = "b1 = b2")

mfx <- slopes(mod, newdata = "mean")
hypotheses(cmp, hypothesis = "b2 = 0.2")

pre <- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35)))
hypotheses(pre, hypothesis = "b1 = b2")

# The `hypothesis` argument can be used to compute standard errors for fitted values
mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)

f <- function(x) predict(x, type = "link", newdata = mtcars)
p <- hypotheses(mod, hypothesis = f)
head(p)

f <- function(x) predict(x, type = "response", newdata = mtcars)
p <- hypotheses(mod, hypothesis = f)
head(p)

# Complex aggregation
# Step 1: Collapse predicted probabilities by outcome level, for each individual
# Step 2: Take the mean of the collapsed probabilities by group and `cyl`
library(dplyr)
library(MASS)
library(dplyr)
library(magrittr)

dat <- transform(mtcars, gear = factor(gear))
mod <- polr(gear ~ factor(cyl) + hp, dat)

aggregation_fun <- function(x) {
    predictions(x, vcov = FALSE) %>%
        mutate(group = ifelse(group %in% c("3", "4"), "3 & 4", "5")) %>%
        summarize(estimate = sum(estimate), .by = c("rowid", "cyl", "group")) %>%
        summarize(estimate = mean(estimate), .by = c("cyl", "group")) %>%
        rename(term = cyl)
}

hypotheses(mod, hypothesis = aggregation_fun)

# Equivalence, non-inferiority, and non-superiority tests
mod <- lm(mpg ~ hp + factor(gear), data = mtcars)
p <- predictions(mod, newdata = "median")
hypotheses(p, equivalence = c(17, 18))

mfx <- avg_slopes(mod, variables = "hp")
hypotheses(mfx, equivalence = c(-.1, .1))

cmp <- avg_comparisons(mod, variables = "gear", hypothesis = ~pairwise)
hypotheses(cmp, equivalence = c(0, 10))

# joint hypotheses: character vector
model <- lm(mpg ~ as.factor(cyl) * hp, data = mtcars)
hypotheses(model, joint = c("as.factor(cyl)6:hp", "as.factor(cyl)8:hp"))

# joint hypotheses: regular expression
hypotheses(model, joint = "cyl")

# joint hypotheses: integer indices
hypotheses(model, joint = 2:3)

# joint hypotheses: different null hypotheses
hypotheses(model, joint = 2:3, hypothesis = 1)
hypotheses(model, joint = 2:3, hypothesis = 1:2)

# joint hypotheses: marginaleffects object
cmp <- avg_comparisons(model)
hypotheses(cmp, joint = "cyl")

# Multiple comparison adjustment
# p values and family-wise confidence intervals
cmp <- avg_comparisons(model)
hypotheses(cmp, multcomp = "hochberg")



```
